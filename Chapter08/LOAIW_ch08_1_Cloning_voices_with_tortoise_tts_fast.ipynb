{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Learn OpenAI Whisper - Chapter 8\n",
        "## Notebook 1: Cloning voices with tortoise-tts-fast\n",
        "\n",
        "This notebook complements the book [Learn OpenAI Whisper](https://a.co/d/1p5k4Tg).\n",
        "\n",
        "This notebook is based on the [TorToiSe-TTS-Fast](https://github.com/152334H/tortoise-tts-fast) project, which drastically boost the performance of [TorToiSe](https://github.com/neonbjb/tortoise-tts), without modifying the base models.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1zxZ7TCYr8hiU7ExY6QuXjPfVldWtcz-s)"
      ],
      "metadata": {
        "id": "w88Rz76tfJiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setting up the environment:\n",
        "   - The code starts by cloning the \"tortoise-tts-fast\" repository and installing the required dependencies.\n",
        "   - It uses `notebook_login()` from the `huggingface_hub` library to authenticate with Hugging Face.\n",
        "   - The necessary imports are made, including `torch`, `torchaudio`, and modules from the `tortoise` package."
      ],
      "metadata": {
        "id": "8VUCMXozLYVF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MR6c04u9Kwk"
      },
      "outputs": [],
      "source": [
        "%%capture loading_libraries\n",
        "!git clone https://github.com/152334H/tortoise-tts-fast\n",
        "%cd tortoise-tts-fast\n",
        "!pip3 install -r requirements.txt --no-deps\n",
        "!pip3 install -e .\n",
        "!pip3 install git+https://github.com/152334H/BigVGAN.git\n",
        "!pip install transformers==4.29.2\n",
        "!pip install voicefixer==0.1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b045a39e-2a3e-4153-bdb5-281500bcd348"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import whoami\n",
        "\n",
        "whoami()\n",
        "# you should see something like {'type': 'user',  'id': '...',  'name': 'Wauplin', ...}"
      ],
      "metadata": {
        "id": "t-Cj-HImlUSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Initializing the TextToSpeech model:\n",
        "   ```python\n",
        "   from tortoise.api import TextToSpeech\n",
        "   tts = TextToSpeech()\n",
        "   ```\n",
        "   - The `TextToSpeech` class is imported from the `tortoise.api` module.\n",
        "   - An instance of `TextToSpeech` is created, which will download all the required models from the Hugging Face hub.\n"
      ],
      "metadata": {
        "id": "myQlFFYD58v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports used through the rest of the notebook.\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import IPython\n",
        "\n",
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_audio, load_voice, load_voices\n",
        "\n",
        "# This will download all the models used by Tortoise from the HuggingFace hub.\n",
        "tts = TextToSpeech()"
      ],
      "metadata": {
        "id": "k9h0XJE-O6_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Tortoise will attempt to mimic voices you provide. It comes pre-packaged\n",
        "#@markdown with some voices you might recognize.\n",
        "\n",
        "#@markdown Let's list all the voices available. These are just some random clips I've gathered\n",
        "#@markdown from the internet as well as a few voices from the training dataset.\n",
        "#@markdown Feel free to add your own clips to the voices/ folder.\n",
        "%cd tortoise-tts-fast\n",
        "%ls tortoise/voices"
      ],
      "metadata": {
        "id": "qY0f2DhaOG5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Selecting a voice:\n",
        "   - The code uses the `os` module to list all the available voice folders in the \"tortoise/voices\" directory.\n",
        "   - It creates a dropdown widget using `Dropdown` from the `ipywidgets` library to allow the user to select a voice folder.\n",
        "   - Another dropdown widget is created to select a specific voice file within the selected voice folder.\n",
        "   - The selected voice can be played using `IPython.display.Audio`."
      ],
      "metadata": {
        "id": "oqi7Fa6J6OF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ipywidgets import Dropdown\n",
        "\n",
        "voices_dir = \"/content/tortoise-tts-fast/tortoise/voices\"\n",
        "\n",
        "# Get a list of all directories in the voices directory\n",
        "voice_names = os.listdir(voices_dir)\n",
        "\n",
        "voice_folder = Dropdown(\n",
        "    options=sorted(voice_names),\n",
        "    description='Select a voice:',\n",
        "    value='tom',\n",
        "    disabled=False,\n",
        "    style={'description_width': 'initial'},\n",
        ")\n",
        "\n",
        "voice_folder"
      ],
      "metadata": {
        "id": "GXPD-X8VZoX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ipywidgets import Dropdown\n",
        "\n",
        "voices_dir = f\"/content/tortoise-tts-fast/tortoise/voices/{voice_folder.value}\"\n",
        "\n",
        "# Get a list of all directories in the voices directory\n",
        "voice_files = os.listdir(voices_dir)\n",
        "\n",
        "voice = Dropdown(\n",
        "    options=sorted(voice_files),\n",
        "    description='Select a voice:',\n",
        "    # value='tom',\n",
        "    disabled=False,\n",
        "    style={'description_width': 'initial'},\n",
        ")\n",
        "\n",
        "voice"
      ],
      "metadata": {
        "id": "KmtkgJ84i-FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pick one of the voices from the output above\n",
        "IPython.display.Audio(filename=f'tortoise/voices/{voice_folder.value}/{voice.value}')"
      ],
      "metadata": {
        "id": "gWw5JDLz6qT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Generating speech with a selected voice:\n",
        "   ```python\n",
        "   text = \"When the season changes, events and gatherings are in full bloom...\"\n",
        "   preset = \"ultra_fast\"\n",
        "   voice = voice_folder.value\n",
        "   voice_samples, conditioning_latents = load_voice(voice)\n",
        "   gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents, preset=preset)\n",
        "   torchaudio.save(generated_filename, gen.squeeze(0).cpu(), 24000)\n",
        "   IPython.display.Audio(generated_filename)\n",
        "   ```\n",
        "   - The text to be spoken is defined in the `text` variable.\n",
        "   - The `preset` variable determines the quality of the generated speech (options: \"ultra_fast\", \"fast\", \"standard\", \"high_quality\").\n",
        "   - The selected voice is loaded using `load_voice` from `tortoise.utils.audio`, which returns `voice_samples` and `conditioning_latents`.\n",
        "   - The `tts_with_preset` method of the `tts` object is called with the text, voice samples, conditioning latents, and preset to generate the speech.\n",
        "   - The generated speech is saved as a WAV file using `torchaudio.save` and played using `IPython.display.Audio`."
      ],
      "metadata": {
        "id": "wh35zmEj63eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the text that will be spoken.\n",
        "text = \"Words, once silent, now dance on digital breath, speaking volumes through the magic of text-to-speech.\" #@param {type:\"string\"}\n",
        "# Pick a \"preset mode\" to determine quality. Options: {\"ultra_fast\", \"fast\" (default), \"standard\", \"high_quality\"}. See docs in api.py\n",
        "preset = \"ultra_fast\" #@param [\"ultra_fast\", \"fast\", \"standard\", \"high_quality\"]"
      ],
      "metadata": {
        "id": "B1TlxVSwOGX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick one of the voices from the output above\n",
        "voice = voice_folder.value\n",
        "\n",
        "#Load it and send it through Tortoise.\n",
        "voice_samples, conditioning_latents = load_voice(voice)\n",
        "gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents,\n",
        "                          preset=preset)\n",
        "\n",
        "generated_filename = f'generated-{preset}-{voice}.wav'\n",
        "torchaudio.save(generated_filename, gen.squeeze(0).cpu(), 24000)\n",
        "IPython.display.Audio(generated_filename)"
      ],
      "metadata": {
        "id": "hRYmzQJhOzz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Generating speech with a random voice:\n",
        "   - Similar to the previous step, but with `voice_samples` and `conditioning_latents` set to `None`, which generates speech using a random voice."
      ],
      "metadata": {
        "id": "XR1COFw17Bna"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16Xs2SSC3BXa"
      },
      "outputs": [],
      "source": [
        "#@markdown Tortoise can also generate speech using a random voice. The voice changes each time you execute this!\n",
        "#@markdown (Note: random voices can be prone to strange utterances)\n",
        "gen = tts.tts_with_preset(text, voice_samples=None, conditioning_latents=None, preset=preset)\n",
        "torchaudio.save('synthetized_voice_sample.wav', gen.squeeze(0).cpu(), 24000)\n",
        "IPython.display.Audio('synthetized_voice_sample.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Using a custom voice:\n",
        "   - The code allows the user to upload their own WAV files (6-10 seconds long) to create a custom voice.\n",
        "   - It creates a custom voice folder using `os.makedirs` and saves the uploaded files in that folder.\n",
        "   - The custom voice is then loaded and used to generate speech, similar to steps 4 and 5."
      ],
      "metadata": {
        "id": "JUQu58ah7OwC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQgw3KeV8Yqb"
      },
      "outputs": [],
      "source": [
        "#@markdown Optionally, upload use your own voice by running the next two cells. I recommend\n",
        "#@markdown you upload at least 2 audio clips. They must be a WAV file, 6-10 seconds long.\n",
        "CUSTOM_VOICE_NAME = \"custom\"\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "custom_voice_folder = f\"tortoise/voices/{CUSTOM_VOICE_NAME}\"\n",
        "os.makedirs(custom_voice_folder)\n",
        "for i, file_data in enumerate(files.upload().values()):\n",
        "  with open(os.path.join(custom_voice_folder, f'{i}.wav'), 'wb') as f:\n",
        "    f.write(file_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJnJwv3R9uWT"
      },
      "outputs": [],
      "source": [
        "# Generate speech with the custotm voice.\n",
        "voice_samples, conditioning_latents = load_voice(CUSTOM_VOICE_NAME)\n",
        "gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents,\n",
        "                          preset=preset)\n",
        "torchaudio.save(f'generated-{CUSTOM_VOICE_NAME}.wav', gen.squeeze(0).cpu(), 24000)\n",
        "IPython.display.Audio(f'generated-{CUSTOM_VOICE_NAME}.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Combining voices:\n",
        "   - The `load_voices` function is used to load multiple voices (in this case, 'pat' and 'william').\n",
        "   - The `tts_with_preset` method is called with the combined voice samples and conditioning latents to generate speech with traits from both voices."
      ],
      "metadata": {
        "id": "bHQx-GMa7aoa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYTk8KUezUr5"
      },
      "outputs": [],
      "source": [
        "# You can also combine conditioning voices. Combining voices produces a new voice\n",
        "# with traits from all the parents.\n",
        "#\n",
        "# Lets see what it would sound like if Picard and Kirk had a kid with a penchant for philosophy:\n",
        "voice_samples, conditioning_latents = load_voices(['freeman', 'deniro'])\n",
        "\n",
        "gen = tts.tts_with_preset(\"Words, once silent, now dance on digital breath, speaking volumes through the magic of text-to-speech.\",\n",
        "                          voice_samples=voice_samples, conditioning_latents=conditioning_latents,\n",
        "                          preset=preset)\n",
        "torchaudio.save('freeman_deniro.wav', gen.squeeze(0).cpu(), 24000)\n",
        "IPython.display.Audio('freeman_deniro.wav')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
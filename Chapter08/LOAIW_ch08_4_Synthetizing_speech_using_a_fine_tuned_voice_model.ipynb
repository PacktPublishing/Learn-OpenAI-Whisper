{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Learn OpenAI Whisper - Chapter 8\n",
        "## Notebook 4: Synthetizing speech using a fine-tuned voice model\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1TxsyV259Aru5EWX9ebrREaW3IgpUT3eG)\n",
        "\n",
        "This notebook complements the book [Learn OpenAI Whisper](https://a.co/d/1p5k4Tg).\n",
        "\n",
        "\n",
        "This notebook is based on the [TorToiSe-TTS-Fast](https://github.com/152334H/tortoise-tts-fast) project, which drastically boost the performance of [TorToiSe](https://github.com/neonbjb/tortoise-tts), without modifying the base models.\n",
        "\n",
        "After creating a fine-tuned voice model using [Notebook 3 of this chapter](https://colab.research.google.com/drive/1qKflIgjPFVDW3qLaL08CV-quth5MwcRd), we then load fine-tuned autoregressive model uring the parameter `--ar-checkpoint`, synthesize speech using the model, and play the generated audio.\n",
        "\n",
        "```\n",
        "./script/tortoise-tts.py --preset very_fast --ar-checkpoint /path/to/checkpoint.pth #...\n",
        "```"
      ],
      "metadata": {
        "id": "3-sUG5ErWQBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Checking NVIDIA GPU:\n",
        "We start by checking if an NVIDIA GPU is available using the `nvidia-smi` command. It prints the GPU information if connected, otherwise it indicates that no GPU is connected."
      ],
      "metadata": {
        "id": "HnPw-2M10wli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "w8sZIMDx03vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Checking Virtual Memory:\n",
        "Next we check the available RAM using the `psutil` library. It prints the amount of available RAM in gigabytes and indicates if a high-RAM runtime is being used."
      ],
      "metadata": {
        "id": "n0UChDVpXOn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "RuDAJXYMYBgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Cloning and Installing tortoise-tts-fast:\n",
        "This cell clones the tortoise-tts-fast repository from GitHub and installs the required dependencies using `pip3`."
      ],
      "metadata": {
        "id": "jV7g9wexz7ib"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYq6vV61iq7N"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/152334H/tortoise-tts-fast\n",
        "%cd tortoise-tts-fast\n",
        "!pip3 install -r requirements.txt --no-deps\n",
        "!pip3 install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Installing Additional Supporting Libraries:\n",
        "Next we install additional libraries such as `transformers`, `voicefixer`, and `BigVGAN` using `pip3`."
      ],
      "metadata": {
        "id": "nuqjRYJUlHOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip3 install transformers==4.29.2\n",
        "!pip3 uninstall voicefixer\n",
        "!pip3 install voicefixer==0.1.2\n",
        "%cd tortoise-tts-fast\n",
        "!pwd\n",
        "!pip3 install git+https://github.com/152334H/BigVGAN.git"
      ],
      "metadata": {
        "id": "3akba7G8_4Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Mounting Google Drive:\n",
        "This cell mounts Google Drive to load the fine-tuned voice model."
      ],
      "metadata": {
        "id": "16q_G6oIltKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "xFt4umCqjlS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Loading a Fine-tuned Autoregressive Voice Model:\n",
        "Next, we set the path to the fine-tuned autoregressive voice model (`gpt_path`) and the text to be synthesized (`text`)."
      ],
      "metadata": {
        "id": "ICtOHXI0hJbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/tortoise-tts-fast/scripts\n",
        "%pwd\n",
        "\n",
        "gpt_path = '/content/gdrive/MyDrive/Generative_AI/Deep_Fakes_Voice/tortoise/WaWF-JRB-audio_20230607.mp3_2023_06_08-13_20/models/120_gpt.pth'\n",
        "text = \"Benny, bring me everyone. EVERYONE!\""
      ],
      "metadata": {
        "id": "lLFwZsAtZDVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Running tortoise_tts.py:\n",
        "The code runs the `tortoise_tts.py` script with the specified arguments, including the `--preset` option for inference speed, the `--ar_checkpoint` option for the fine-tuned model path, the `-o` option for output file name, and the text to be synthesized."
      ],
      "metadata": {
        "id": "Lr0ATIW50vRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python tortoise_tts.py --preset fast --ar_checkpoint $gpt_path -o \"152.wav\" $text"
      ],
      "metadata": {
        "id": "NZmmcwH61Fkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Playing the Synthesized Audio:\n",
        "Finally, the code uses IPython to display and play the synthesized audio file."
      ],
      "metadata": {
        "id": "iUkp1SKW0zdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "IPython.display.Audio('/content/tortoise-tts-fast/scripts/results/random_00_00.wav')"
      ],
      "metadata": {
        "id": "G3zQEdLk2ywp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
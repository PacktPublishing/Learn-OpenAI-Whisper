{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Using Whisper in Google Colab\n",
        "This notebook provides a simple template for using OpenAI's Whisper for audio transcription in Google Colab.\n",
        "\n",
        "##Step 1: Install Whisper\n",
        "Run the cell below to install Whisper."
      ],
      "metadata": {
        "id": "DQlDUDCte1d4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcZajWk8eG6o"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2: Upload Your Audio File\n",
        "Use the file upload feature of Google Colab to upload your audio file.\n",
        "\n",
        "##Step 3: Transcribe Audio\n",
        "Replace 'your_audio_file_here.wav' with your file's name and run the cell."
      ],
      "metadata": {
        "id": "WrX-6RDFfL6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"medium.en\")\n",
        "result = model.transcribe(\"/content/Learn_OAI_Whisper_Sample_Audio01.m4a\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1f-bkrufLbM",
        "outputId": "224ee8a5-6268-49bd-9408-9020d6d5d46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:34<00:00, 44.9MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hello, this is Josue Batista. I am the author of the book, Learn OpenAI Whisper, transform your understanding of generative AI through robust and accurate speech processing solutions. This is an audio sample that you can use to try and test and enhance your own implementation of Whisper. Good luck!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4: Review the Transcription\n",
        "The transcription will be displayed in the output of the cell."
      ],
      "metadata": {
        "id": "PoJJUwg0fZbo"
      }
    }
  ]
}